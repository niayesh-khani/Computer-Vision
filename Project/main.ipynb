{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ36cMwH0tGn",
        "outputId": "93c3ec25-6cc9-429d-ec9b-08330b857da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: rarfile in /usr/local/lib/python3.10/dist-packages (4.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.6.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import gdown\n",
        "!apt-get install unrar\n",
        "!pip install gdown rarfile\n",
        "import rarfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "# from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu3dj3qcwkqB",
        "outputId": "ab58f0a7-9cc1-48ac-8571-adfb07ae74da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1sA0waMKbP8ffMlb1NRqxIFhsymuq2Frx\n",
            "From (redirected): https://drive.google.com/uc?id=1sA0waMKbP8ffMlb1NRqxIFhsymuq2Frx&confirm=t&uuid=2050af80-dfa9-42d6-bc38-03a283643df3\n",
            "To: /content/datasets/CASIA_faceAntisp.rar\n",
            "100%|██████████| 876M/876M [00:14<00:00, 61.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "file_id = '1sA0waMKbP8ffMlb1NRqxIFhsymuq2Frx'\n",
        "output_dir = 'datasets'\n",
        "rar_file = os.path.join(output_dir, 'CASIA_faceAntisp.rar')\n",
        "\n",
        "#make the directory\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', rar_file, quiet=False)\n",
        "extract_dir = 'CASIA_faceAntisp'\n",
        "if not os.path.exists(extract_dir):\n",
        "    os.makedirs(extract_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yWMel_Oz30bG"
      },
      "outputs": [],
      "source": [
        "with rarfile.RarFile(rar_file) as rf:\n",
        "    rf.extractall(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7gFljAVA0xQA"
      },
      "outputs": [],
      "source": [
        "train_folder_path = 'CASIA_faceAntisp/train_release'\n",
        "test_folder_path = 'CASIA_faceAntisp/test_release'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VFjALpyB02_2"
      },
      "outputs": [],
      "source": [
        "labels = {\n",
        "    'HR_1': 1,\n",
        "    'HR_2': 0,\n",
        "    'HR_3': 0,\n",
        "    'HR_4': 1,\n",
        "    '1': 1,\n",
        "    '2': 1,\n",
        "    '3': 0,\n",
        "    '4': 0,\n",
        "    '5': 0,\n",
        "    '6': 0,\n",
        "    '7': 0,\n",
        "    '8': 0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_frame_labels_dict(folder_path, labels):\n",
        "    frame_labels_dict = {}\n",
        "\n",
        "    for folder in os.listdir(folder_path):\n",
        "        path = os.path.join(folder_path, folder)\n",
        "        if os.path.isdir(path):\n",
        "            # Iterate through each file in the folder\n",
        "            for file in os.listdir(path):\n",
        "                file_name, file_extension = os.path.splitext(file)\n",
        "                # if file_name in labels:\n",
        "                label = labels[file_name]\n",
        "                frame_labels_dict[f\"{folder}_{file_name}\"] = label\n",
        "\n",
        "    return frame_labels_dict"
      ],
      "metadata": {
        "id": "LbIdPuChtJcm"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1DkxbuAm0pdu"
      },
      "outputs": [],
      "source": [
        "train_frame_labels_dict = create_frame_labels_dict(train_folder_path, labels)\n",
        "test_frame_labels_dict = create_frame_labels_dict(test_folder_path, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_directory(directory_path):\n",
        "    if not os.path.exists(directory_path):\n",
        "        os.makedirs(directory_path)\n",
        "    else:\n",
        "        # Empty the directory if it already exists\n",
        "        for filename in os.listdir(directory_path):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            try:\n",
        "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                    os.unlink(file_path)\n",
        "                elif os.path.isdir(file_path):\n",
        "                    shutil.rmtree(file_path)\n",
        "            except Exception as e:\n",
        "                print(f'Failed to delete {file_path}. Reason: {e}')"
      ],
      "metadata": {
        "id": "qwxyRE56uYDE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_random_frames(folder_path, output_dir, num_frames=3):\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for folder in os.listdir(folder_path):\n",
        "        path = os.path.join(folder_path, folder)\n",
        "        if os.path.isdir(path):\n",
        "            for file in os.listdir(path):\n",
        "                file_name, file_extension = os.path.splitext(file)\n",
        "                video_path = os.path.join(path, file)\n",
        "                video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "                # Get total number of frames\n",
        "                total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "                if total_frames > num_frames:\n",
        "                    # Generate random frame numbers\n",
        "                    frame_numbers = sorted(random.sample(range(total_frames), num_frames))\n",
        "\n",
        "                    for i, frame_num in enumerate(frame_numbers):\n",
        "                        # Set the video capture to the specified frame\n",
        "                        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
        "\n",
        "                        # Read the specified frame\n",
        "                        success, frame = video_capture.read()\n",
        "                        if success:\n",
        "                            frame_output_dir = os.path.join(output_dir, f\"{folder}_{file_name}\")\n",
        "                            if not os.path.exists(frame_output_dir):\n",
        "                                os.makedirs(frame_output_dir)\n",
        "                            frame_path = os.path.join(frame_output_dir, f\"{i+1}.jpg\")\n",
        "                            cv2.imwrite(frame_path, frame)\n",
        "                        else:\n",
        "                            print(f\"Warning: Could not read frame {frame_num} from video {file}\")\n",
        "                else:\n",
        "                    print(f\"Warning: Video {file} has only {total_frames} frames. Skipping.\")\n",
        "\n",
        "                video_capture.release()"
      ],
      "metadata": {
        "id": "ENZ2C7v_vVN1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hT0rD1IV0Chf"
      },
      "outputs": [],
      "source": [
        "train_frames_dir = 'train_frames'\n",
        "make_directory(train_frames_dir)\n",
        "\n",
        "extract_random_frames(train_folder_path, train_frames_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_faces_from_frames(folder_path, output_dir):\n",
        "    # Load Haar cascade for face detection\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for folder in os.listdir(folder_path):\n",
        "        path = os.path.join(folder_path, folder)\n",
        "        if os.path.isdir(path):\n",
        "            for file in os.listdir(path):\n",
        "                file_path = os.path.join(path, file)\n",
        "                frame = cv2.imread(file_path)\n",
        "\n",
        "                # Check if the frame was read successfully\n",
        "                if frame is None:\n",
        "                    print(f\"Warning: Could not read frame {file}. Skipping this frame.\")\n",
        "                    continue\n",
        "\n",
        "                gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "                # if len(faces) == 0:\n",
        "                #     print(f\"Warning: No faces detected in frame {file}.\")\n",
        "\n",
        "                for i, (x, y, w, h) in enumerate(faces):\n",
        "                    face = frame[y:y+h, x:x+w]\n",
        "                    frame_output_dir = os.path.join(output_dir, folder)\n",
        "                    if not os.path.exists(frame_output_dir):\n",
        "                        os.makedirs(frame_output_dir)\n",
        "                    face_filename = f\"{os.path.splitext(file)[0]}.jpg\"\n",
        "                    face_path = os.path.join(frame_output_dir, face_filename)\n",
        "                    cv2.imwrite(face_path, face)\n"
      ],
      "metadata": {
        "id": "eSYRI-WR461B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ixjuUB5vf9ok"
      },
      "outputs": [],
      "source": [
        "# make directory for store the detected faces\n",
        "train_faces_dir = 'train_faces'\n",
        "make_directory(train_faces_dir)\n",
        "\n",
        "extract_faces_from_frames(train_frames_dir, train_faces_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to extract frequency features from frames\n",
        "def extract_frequency_features(image):\n",
        "    resized_image = cv2.resize(image, (224, 224))\n",
        "    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "    f_transform = np.fft.fft2(gray_image)\n",
        "    f_magnitude = np.abs(f_transform)\n",
        "    return f_magnitude.flatten()"
      ],
      "metadata": {
        "id": "RZqo2Z_I-81W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_frequency_frame_dict(folder_path):\n",
        "    frequency_frame_dict = {}\n",
        "\n",
        "    for folder in os.listdir(folder_path):\n",
        "        path = os.path.join(folder_path, folder)\n",
        "        if os.path.isdir(path):\n",
        "            for frame_file in os.listdir(path):\n",
        "                frame_path = os.path.join(path, frame_file)\n",
        "                frame_image = cv2.imread(frame_path)\n",
        "\n",
        "                # Check if the frame was loaded correctly\n",
        "                if frame_image is None:\n",
        "                    print(f\"Warning: Could not read image {frame_file}. Skipping this frame.\")\n",
        "                    continue\n",
        "\n",
        "                # Extract frequency features from the frame image\n",
        "                feature = extract_frequency_features(frame_image)\n",
        "                frame_name = os.path.splitext(frame_file)[0]\n",
        "                frequency_frame_dict[f\"{folder}_{frame_name}\"] = feature\n",
        "\n",
        "    return frequency_frame_dict"
      ],
      "metadata": {
        "id": "zl1ZYYxA-KyO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wMfg65YngGbG"
      },
      "outputs": [],
      "source": [
        "#dictionary to store frame names and corresponding features\n",
        "features_dict = create_frequency_frame_dict(train_faces_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_frames_dir = 'test_frames'\n",
        "make_directory(test_frames_dir)\n",
        "\n",
        "test_faces_dir = 'test_faces'\n",
        "make_directory(test_faces_dir)\n",
        "\n",
        "extract_random_frames(test_folder_path, test_frames_dir,1)\n",
        "\n",
        "extract_faces_from_frames(test_frames_dir, test_faces_dir)"
      ],
      "metadata": {
        "id": "HC6CFaaaOkXx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_dict_test = create_frequency_frame_dict(test_faces_dir)"
      ],
      "metadata": {
        "id": "ad-eARQbiApK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load frames and labels into numpy arrays\n",
        "def load_frames_and_labels_from_dict(frame_labels_dict, frames_dir):\n",
        "    frames = []\n",
        "    labels = []\n",
        "    for frame_name, label in frame_labels_dict.items():\n",
        "        for frame_name_path in os.listdir(os.path.join(frames_dir, frame_name)):\n",
        "            frame_path = os.path.join(os.path.join(frames_dir, frame_name), frame_name_path)\n",
        "            frame = cv2.imread(frame_path)\n",
        "            if frame is not None:\n",
        "                frames.append(cv2.resize(frame, (224, 224)))\n",
        "                labels.append(label)\n",
        "            else:\n",
        "                print(f\"Warning: Could not read image1 {frame_path}\")\n",
        "    frames = np.array(frames) / 255.0  # Normalize\n",
        "    labels = np.array(labels)\n",
        "    return frames, labels\n",
        "\n",
        "# Load frequency features and labels into numpy arrays\n",
        "def load_frequency_features_and_labels_from_dict(features_dict, frames_dir):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for frame_name, label in features_dict.items():\n",
        "        desired_part = '_'.join(frame_name.rsplit('_', 1)[:-1])\n",
        "        features.append(label)\n",
        "        labels.append(train_frame_labels_dict[desired_part])\n",
        "        # for frame_name_path in os.listdir(os.path.join(frames_dir, frame_name)):\n",
        "        #   frame = cv2.imread(frame_path)\n",
        "        #   if frame is not None:\n",
        "        #       feature = extract_frequency_features(frame)\n",
        "        #       features.append(feature)\n",
        "        #       labels.append(label)\n",
        "        #       # print(f\"Extracted feature shape for {frame_name}: {feature.shape}\")  # Debugging line\n",
        "        #   else:\n",
        "        #       print(f\"Warning: Could not read image {frame_path}\")\n",
        "    features = np.array(features)\n",
        "    labels = np.array(labels)\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "QAIjrTAKV-pK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_frames, train_labels = load_frames_and_labels_from_dict(train_frame_labels_dict, train_frames_dir)"
      ],
      "metadata": {
        "id": "fDrwQXc7c9vC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_faces_frame, train_faces_label = load_frames_and_labels_from_dict(train_frame_labels_dict, train_frames_dir)"
      ],
      "metadata": {
        "id": "oSil6F9Kc-n9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_frequency_frame, train_frequency_label = load_frequency_features_and_labels_from_dict(features_dict, train_frames_dir)"
      ],
      "metadata": {
        "id": "bqOqreqRdBjT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_frames, test_labels = load_frames_and_labels_from_dict(test_frame_labels_dict, test_frames_dir)"
      ],
      "metadata": {
        "id": "UCxSpdzRcxhJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_faces_frame, test_faces_label = load_frames_and_labels_from_dict(test_frame_labels_dict, test_frames_dir)"
      ],
      "metadata": {
        "id": "ejsfuF7Jc1ls"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_frequency_frame, test_frequency_label = load_frequency_features_and_labels_from_dict(features_dict_test, test_frames_dir)"
      ],
      "metadata": {
        "id": "6p_Q3Ewbc3av"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_train_samples = min(len(train_frames), len(train_faces_frame), len(train_frequency_frame), len(train_labels))\n",
        "min_test_samples = min(len(test_frames), len(test_faces_frame), len(test_labels))\n",
        "\n",
        "train_frames = train_frames[:min_train_samples]\n",
        "train_faces_frame = train_faces_frame[:min_train_samples]\n",
        "train_frequency_frame = train_frequency_frame[:min_train_samples]\n",
        "train_labels = train_labels[:min_train_samples]\n",
        "\n",
        "test_frames = test_frames[:min_test_samples]\n",
        "test_faces_frame = test_faces_frame[:min_test_samples]\n",
        "test_frequency_frame = train_frequency_frame[:min_test_samples]\n",
        "test_labels = test_labels[:min_test_samples]"
      ],
      "metadata": {
        "id": "UaozVY0Ft2cC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the model for frames\n",
        "frame_input = Input(shape=(224, 224, 3), name='frame_input')\n",
        "base_model_frame = MobileNet(weights='imagenet', include_top=False, input_tensor=frame_input)\n",
        "for layer in base_model_frame.layers:\n",
        "    layer.trainable = False\n",
        "    # Rename layers to avoid conflicts\n",
        "    layer._name = 'frame_' + layer.name\n",
        "\n",
        "x_frame = base_model_frame.output\n",
        "x_frame = Flatten(name='frame_flatten')(x_frame)\n",
        "x_frame = Dense(1024, activation='relu', name='frame_dense')(x_frame)\n",
        "x_frame = Dropout(0.5, name='frame_dropout')(x_frame)\n",
        "frame_output = Dense(1, activation='sigmoid', name='frame_output')(x_frame)\n",
        "frame_model = Model(inputs=frame_input, outputs=frame_output, name='frame_model')\n",
        "\n",
        "# Define the model for face frames (similar modifications)\n",
        "face_input = Input(shape=(224, 224, 3), name='face_input')\n",
        "base_model_face = MobileNet(weights='imagenet', include_top=False, input_tensor=face_input)\n",
        "for layer in base_model_face.layers:\n",
        "    layer.trainable = False\n",
        "    # Rename layers to avoid conflicts\n",
        "    layer._name = 'face_' + layer.name\n",
        "\n",
        "x_face = base_model_face.output\n",
        "x_face = Flatten(name='face_flatten')(x_face)\n",
        "x_face = Dense(1024, activation='relu', name='face_dense')(x_face)\n",
        "x_face = Dropout(0.5, name='face_dropout')(x_face)\n",
        "face_output = Dense(1, activation='sigmoid', name='face_output')(x_face)\n",
        "face_model = Model(inputs=face_input, outputs=face_output, name='face_model')\n",
        "\n",
        "# Define the model for frequency inputs (reshaped to 224x224)\n",
        "frequency_input = Input(shape=(224*224,), name='frequency_input')\n",
        "x_frequency = Dense(1024, activation='relu', name='frequency_dense')(frequency_input)\n",
        "x_frequency = Dropout(0.5, name='frequency_dropout')(x_frequency)\n",
        "frequency_output = Dense(1, activation='sigmoid', name='frequency_output')(x_frequency)\n",
        "frequency_model = Model(inputs=frequency_input, outputs=frequency_output, name='frequency_model')\n",
        "\n",
        "# Combine the models with unique layer names\n",
        "combined_input = concatenate([frame_model.output, face_model.output, frequency_model.output], name='combined_concatenate')\n",
        "x_combined = Dense(1024, activation='relu', name='combined_dense_1')(combined_input)\n",
        "x_combined = Dropout(0.5, name='combined_dropout_1')(x_combined)\n",
        "combined_output = Dense(1, activation='sigmoid', name='combined_output')(x_combined)\n",
        "combined_model = Model(inputs=[frame_input, face_input, frequency_input], outputs=combined_output, name='combined_model')\n",
        "\n",
        "# Compile the combined model\n",
        "combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Add early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "combined_model.fit([train_frames, train_faces_frame, train_frequency_frame], train_labels,\n",
        "                   epochs=5, batch_size=32,\n",
        "                   validation_data=([test_frames, test_faces_frame, test_frequency_frame[:(len(test_frames))]], test_labels),\n",
        "                   callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "fEjAskdMMTDO",
        "outputId": "6bde5f6e-623f-4390-902b-b20b3f5d6f7c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "22/22 [==============================] - 246s 9s/step - loss: 0.6512 - accuracy: 0.6574 - val_loss: 0.6411 - val_accuracy: 0.6667\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 187s 9s/step - loss: 0.6398 - accuracy: 0.6662 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 186s 9s/step - loss: 0.6395 - accuracy: 0.6662 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
            "Epoch 4/5\n",
            " 7/22 [========>.....................] - ETA: 1:42 - loss: 0.6265 - accuracy: 0.6830"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-bc8ac38ca301>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Train the model with early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m combined_model.fit([train_frames, train_faces_frame, train_frequency_frame], train_labels,\n\u001b[0m\u001b[1;32m     54\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_faces_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_frequency_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id_test = '1vUgpR0RVdrmSI_YDpR9YTCqTiM8m040a'\n",
        "output_dir = './'\n",
        "rar_file_test = os.path.join(output_dir, 'dataset.rar')\n",
        "\n",
        "#make the directory\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id_test}', rar_file_test, quiet=False)\n",
        "extract_dir_test = 'Test2'\n",
        "if not os.path.exists(extract_dir_test):\n",
        "    os.makedirs(extract_dir_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5ZCA4IZ3L1J",
        "outputId": "fa94cef4-b2bd-4695-d38b-63b4b183ad31"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1vUgpR0RVdrmSI_YDpR9YTCqTiM8m040a\n",
            "From (redirected): https://drive.google.com/uc?id=1vUgpR0RVdrmSI_YDpR9YTCqTiM8m040a&confirm=t&uuid=4f0ac156-2b8a-48f2-ba30-faa1b8e1a700\n",
            "To: /content/dataset.rar\n",
            "100%|██████████| 138M/138M [00:02<00:00, 50.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with rarfile.RarFile(rar_file_test) as rft:\n",
        "    rft.extractall(extract_dir_test)"
      ],
      "metadata": {
        "id": "pdmNM2-B4fix"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test2_folder_path = 'Test2'\n",
        "\n",
        "test2_frames_dir = 'test2_frames'\n",
        "make_directory(test2_frames_dir)\n",
        "\n",
        "test2_faces_dir = 'test2_faces'\n",
        "make_directory(test2_faces_dir)\n",
        "\n",
        "with open('datasets.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "cleaned_lines = [line.strip() for line in lines]\n",
        "\n",
        "\n",
        "test2_frames2 = extract_random_frames(test2_folder_path, test2_frames_dir,1)\n",
        "test2_faces2 = extract_faces_from_frames(test2_frames_dir, test2_faces_dir)"
      ],
      "metadata": {
        "id": "4JyU-aGq51ro"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test2_freqs2 = features_dict_test2 = create_frequency_frame_dict(test2_faces_dir)"
      ],
      "metadata": {
        "id": "CqXQ7Or-Cem5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = combined_model.predict([test2_frames2, test2_faces2, test2_freqs2])\n",
        "# Save the predictions to a CSV file\n",
        "results = pd.DataFrame({\n",
        "    'filename': frame_names,\n",
        "    'prediction': predictions.flatten()\n",
        "})\n",
        "\n",
        "results.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "jh5VH-hZC9kB",
        "outputId": "a138eca5-1ce0-4d53-b7bf-91ce393ea220"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'dict\\'> containing {\"<class \\'str\\'>\"} keys and {\"<class \\'numpy.ndarray\\'>\"} values)', \"<class 'NoneType'>\"}), <class 'NoneType'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-73fd01f6cc4c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest2_frames2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest2_faces2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest2_freqs2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Save the predictions to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m results = pd.DataFrame({\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'filename'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mframe_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'prediction'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1106\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1107\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'dict\\'> containing {\"<class \\'str\\'>\"} keys and {\"<class \\'numpy.ndarray\\'>\"} values)', \"<class 'NoneType'>\"}), <class 'NoneType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Paths\n",
        "train_frames_dir = 'train_frames'\n",
        "train_face_dir = 'train_faces'\n",
        "\n",
        "# Function to extract HOG features (example for image feature extraction)\n",
        "def extract_hog_features(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    features, _ = hog(gray_image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
        "    return features\n",
        "\n",
        "# Function to extract frequency features\n",
        "def extract_frequency_features(image):\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    f_transform = np.fft.fft2(gray_image)\n",
        "    f_magnitude = np.abs(f_transform)\n",
        "    return f_magnitude.flatten()\n",
        "\n",
        "# Load images and extract features\n",
        "whole_image_features = []\n",
        "cropped_face_features = []\n",
        "frequency_features = []\n",
        "labels = []  # Assuming you have a way to get labels for your images\n",
        "\n",
        "for frame_file in os.listdir(train_frames_dir):\n",
        "    # Load whole image\n",
        "    frame_path = os.path.join(train_frames_dir, frame_file)\n",
        "    whole_image = cv2.imread(frame_path)\n",
        "    if whole_image is None:\n",
        "        continue\n",
        "\n",
        "    # Extract features from whole image\n",
        "    whole_image_feature = extract_hog_features(whole_image)\n",
        "    whole_image_features.append(whole_image_feature)\n",
        "\n",
        "    # Load cropped face\n",
        "    face_path = os.path.join(train_face_dir, frame_file)\n",
        "    if os.path.exists(face_path):\n",
        "        cropped_face = cv2.imread(face_path)\n",
        "        if cropped_face is not None:\n",
        "            cropped_face_feature = extract_hog_features(cropped_face)\n",
        "        else:\n",
        "            cropped_face_feature = np.zeros_like(whole_image_feature)  # Handle missing face case\n",
        "    else:\n",
        "        cropped_face_feature = np.zeros_like(whole_image_feature)  # Handle missing face case\n",
        "    cropped_face_features.append(cropped_face_feature)\n",
        "\n",
        "    # Extract frequency features\n",
        "    freq_features = extract_frequency_features(whole_image)\n",
        "    frequency_features.append(freq_features)\n",
        "\n",
        "    # Append the corresponding label\n",
        "    # You need to implement your way of getting labels here\n",
        "    # labels.append(your_label_function(frame_file))\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "whole_image_features = np.array(whole_image_features)\n",
        "cropped_face_features = np.array(cropped_face_features)\n",
        "frequency_features = np.array(frequency_features)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "VnMeUSD_OjiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure frequency features are scaled to have the same range as other features\n",
        "scaler = StandardScaler()\n",
        "frequency_features_scaled = scaler.fit_transform(frequency_features)\n",
        "\n",
        "# Combine all features\n",
        "combined_features = np.concatenate((whole_image_features, cropped_face_features, frequency_features_scaled), axis=1)\n"
      ],
      "metadata": {
        "id": "SNOCGxIjOljv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_classifier.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "_DikeMO9OoQt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}